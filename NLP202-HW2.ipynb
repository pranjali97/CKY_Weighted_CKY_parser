{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "94170e70-13f4-44d6-bc9b-adfc69abf4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (0.9.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8f463268-f745-42aa-9d5a-047a6904c9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5aac5b0-f44b-4c20-9b04-d6344f319517",
   "metadata": {},
   "source": [
    "## Part : 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "35999d3e-4ba2-4f07-b6c4-b343acd84760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grammar rules\n",
    "\n",
    "grammar_rules = {'S': [['NP', 'VP']],\n",
    "         'NP':[['JJ', 'NP'], ['British'], ['waffles'], ['Falklands'], ['left']],\n",
    "         'VP': [['VP', 'NP'], ['VP', 'PP'], ['left'], ['waffles']],\n",
    "         'PP' : [['P', 'NP']],\n",
    "         'P' : [['on']],\n",
    "        'JJ': [['British']]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3345c462-8723-4413-ab75-05932fedc8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CKY_parser(tokens):\n",
    "    print(tokens)\n",
    "    token_len = len(tokens)\n",
    "    \n",
    "    # set up table\n",
    "    \n",
    "    table = [[set([]) for j in range(token_len)] for i in range(token_len)]\n",
    "    \n",
    "    for j in range(0, token_len):\n",
    "        for pos, rule in grammar_rules.items():\n",
    "            for rule_token in rule:\n",
    "                if len(rule_token) == 1 and rule_token[0] == tokens[j]:\n",
    "                    table[j][j].add(pos)\n",
    "\n",
    "        for i in range(j, -1, -1):\n",
    "            for k in range(i, j):\n",
    "                for pos, rule in grammar_rules.items():\n",
    "                    for rule_token in rule:\n",
    "                        if len(rule_token) == 2 and rule_token[0] in table[i][k] and rule_token[1] in table[k+1][j]:\n",
    "                            table[i][j].add(pos)\n",
    "               \n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "459d7433-03d5-45b2-a5a6-eb55d419cbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['British', 'left', 'waffles', 'on', 'Falklands']\n",
      "------------  ------------  ------------  -----  -----------\n",
      "{'JJ', 'NP'}  {'S', 'NP'}   {'S'}         set()  {'S'}\n",
      "set()         {'VP', 'NP'}  {'S', 'VP'}   set()  {'S', 'VP'}\n",
      "set()         set()         {'VP', 'NP'}  set()  {'VP'}\n",
      "set()         set()         set()         {'P'}  {'PP'}\n",
      "set()         set()         set()         set()  {'NP'}\n",
      "------------  ------------  ------------  -----  -----------\n"
     ]
    }
   ],
   "source": [
    "sent = 'British left waffles on Falklands'\n",
    "\n",
    "words = sent.split(' ')\n",
    "parse_table = CKY_parser(words)\n",
    "\n",
    "print(tabulate(parse_table))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6355dee1-bd19-429f-bc0a-327449d689e3",
   "metadata": {},
   "source": [
    "## Part : 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5325daac-d1bd-4d7e-98f8-f27e3e57a47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_rules = {'S': [(['NP', 'VP'],1.0)],\n",
    "         'NP':[(['NP', 'PP'], 0.4), (['astronomers'],0.4), (['ears'],0.18), (['saw'],0.04), (['stars'], 0.18), (['telescopes'],0.1)],\n",
    "         'VP': [(['V', 'NP'], 0.7), (['VP', 'PP'], 0.3)],\n",
    "         'PP' : [(['P', 'NP'], 1.0)],\n",
    "         'P' : [(['with'], 1.0)],\n",
    "         'V' : [(['saw'], 1.0)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bd6d7b82-dde4-4d7d-bbb4-c44a63b9dcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCKY_parser(tokens):\n",
    "    print(tokens)\n",
    "    token_len = len(tokens)\n",
    "    \n",
    "    # set up table\n",
    "    \n",
    "    table = [[set([]) for j in range(token_len)] for i in range(token_len)]\n",
    "    \n",
    "    for j in range(0, token_len):\n",
    "        for pos, rule in grammar_rules.items():\n",
    "            for rule_token in rule:\n",
    "                if len(rule_token[0]) == 1 and rule_token[0][0] == tokens[j]:\n",
    "                    if len(table[j][j]) == 0:\n",
    "                        table[j][j].add((pos,rule_token[1]))\n",
    "                    else:\n",
    "                        if rule_token[1] > list(table[0][0])[0][1]:\n",
    "                            table[j][j] = set([])\n",
    "                            table[j][j].add((pos,rule_token[1]))\n",
    "\n",
    "        for i in range(j, -1, -1):\n",
    "            for k in range(i, j):\n",
    "                for pos, rule in grammar_rules.items():\n",
    "                    for rule_token in rule:\n",
    "                        if len(rule_token[0]) == 2:\n",
    "                            if len(list(table[i][k])) > 0:\n",
    "                                i_k_eles = [item for item in list(table[i][k]) if rule_token[0][0] == item[0]]\n",
    "                                for i_k_ele in i_k_eles:\n",
    "                                    if len(list(table[k+1][j])) > 0:\n",
    "                                        k_j_eles = [item for item in list(table[k+1][j]) if rule_token[0][1] == item[0]]\n",
    "                                        for k_j_ele in k_j_eles:\n",
    "                                            prob = rule_token[1] * i_k_ele[1] * k_j_ele[1]\n",
    "                                            if len(table[i][j]) == 0:\n",
    "                                                table[i][j].add((pos,round(prob, 5)))\n",
    "                                            else:\n",
    "                                                if prob > list(table[i][j])[0][1]:\n",
    "                                                    table[i][j].add((pos,round(prob, 5)))\n",
    "                                               \n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5ba7e483-5916-49c1-a55f-7be200650f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['astronomers', 'saw', 'stars', 'with', 'ears']\n",
      "-------------  ------------  ---------------  ------------  -----------------\n",
      "{('NP', 0.4)}  set()         {('S', 0.0504)}  set()         {('S', 0.00363)}\n",
      "set()          {('V', 1.0)}  {('VP', 0.126)}  set()         {('VP', 0.00907)}\n",
      "set()          set()         {('NP', 0.18)}   set()         {('NP', 0.01296)}\n",
      "set()          set()         set()            {('P', 1.0)}  {('PP', 0.18)}\n",
      "set()          set()         set()            set()         {('NP', 0.18)}\n",
      "-------------  ------------  ---------------  ------------  -----------------\n"
     ]
    }
   ],
   "source": [
    "sent = 'astronomers saw stars with ears'\n",
    "\n",
    "words = sent.split(' ')\n",
    "parse_table = PCKY_parser(words)\n",
    "print(tabulate(parse_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fc620b81-a3cf-4310-8a4e-882f5b290b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tree(table, words):\n",
    "    parse_tree = ['S']\n",
    "    rows = len(table)\n",
    "    for i in range(rows):\n",
    "        rules = grammar_rules[list(table[i][rows-1])[0][0]]\n",
    "        if len(rules) == 1:\n",
    "            lhs = []\n",
    "            lhs.append(rules[0][0][0])\n",
    "            lhs.append(words[i])\n",
    "            rhs = []\n",
    "            rhs.append(rules[0][0][1])\n",
    "            parse_tree.append(lhs)\n",
    "            parse_tree.append(rhs)\n",
    "        elif len(rules) == 2:\n",
    "            lhs = []\n",
    "            rhs = []\n",
    "            if rules[0][1] > rules[1][1]:\n",
    "                lhs.append(rules[0][0][0])\n",
    "                lhs.append(words[i])\n",
    "                rhs.append(rules[0][0][1])\n",
    "                parse_tree.append(lhs)\n",
    "                parse_tree.append(rhs)\n",
    "        elif list(table[i][rows-1])[0][0] == 'NP':\n",
    "            lhs = []\n",
    "            lhs.append(list(table[i][rows-1])[0][0])\n",
    "            lhs.append(words[i])\n",
    "            parse_tree.append(lhs)\n",
    "            \n",
    "    return parse_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "90206042-c2c7-49bb-b62e-91e7ae9078dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S',\n",
       " ['NP', 'astronomers'],\n",
       " ['VP'],\n",
       " ['V', 'saw'],\n",
       " ['NP'],\n",
       " ['NP', 'stars'],\n",
       " ['P', 'with'],\n",
       " ['NP'],\n",
       " ['NP', 'ears']]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_tree_string = generate_tree(parse_table, words)\n",
    "parse_tree_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "178f9fd7-84cc-45b7-aa57-a950430520a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00363\n"
     ]
    }
   ],
   "source": [
    "# probability of parse tree\n",
    "\n",
    "print(list(parse_table[0][4])[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414fcb02-7949-43e2-9cbc-3bf3cee092ee",
   "metadata": {},
   "source": [
    "## Part : 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f3820545-f45c-4fbf-a8bb-5109f3a76fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WCKY_parser(tokens):\n",
    "    print(tokens)\n",
    "    token_len = len(tokens)\n",
    "    \n",
    "    # set up table\n",
    "    \n",
    "    table = [[set([]) for j in range(token_len)] for i in range(token_len)]\n",
    "    \n",
    "    for j in range(0, token_len):\n",
    "        for pos, rule in grammar_rules.items():\n",
    "            for rule_token in rule:\n",
    "                if len(rule_token[0]) == 1 and rule_token[0][0] == tokens[j]:\n",
    "                    table[j][j].add((pos,rule_token[1]))\n",
    "\n",
    "        for i in range(j, -1, -1):\n",
    "            for k in range(i, j):\n",
    "                for pos, rule in grammar_rules.items():\n",
    "                    for rule_token in rule:\n",
    "                        if len(rule_token[0]) == 2:\n",
    "                            if len(list(table[i][k])) > 0:\n",
    "                                i_k_eles = [item for item in list(table[i][k]) if rule_token[0][0] == item[0]]\n",
    "                                for i_k_ele in i_k_eles:\n",
    "                                    if len(list(table[k+1][j])) > 0:\n",
    "                                        k_j_eles = [item for item in list(table[k+1][j]) if rule_token[0][1] == item[0]]\n",
    "                                        for k_j_ele in k_j_eles:\n",
    "                                            prob = rule_token[1] * i_k_ele[1] * k_j_ele[1]\n",
    "                                            table[i][j].add((pos,round(prob, 5)))\n",
    "           \n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "79457e90-e8f4-4884-be7a-0090c2a71afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['astronomers', 'saw', 'stars', 'with', 'ears']\n",
      "-------------  --------------------------  ---------------  ------------  ---------------------------------\n",
      "{('NP', 0.4)}  set()                       {('S', 0.0504)}  set()         {('S', 0.00363), ('S', 0.00272)}\n",
      "set()          {('V', 1.0), ('NP', 0.04)}  {('VP', 0.126)}  set()         {('VP', 0.0068), ('VP', 0.00907)}\n",
      "set()          set()                       {('NP', 0.18)}   set()         {('NP', 0.01296)}\n",
      "set()          set()                       set()            {('P', 1.0)}  {('PP', 0.18)}\n",
      "set()          set()                       set()            set()         {('NP', 0.18)}\n",
      "-------------  --------------------------  ---------------  ------------  ---------------------------------\n"
     ]
    }
   ],
   "source": [
    "sent = 'astronomers saw stars with ears'\n",
    "\n",
    "words = sent.split(' ')\n",
    "parse_table = WCKY_parser(words)\n",
    "print(tabulate(parse_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "65ebcdc2-d373-4a00-b10b-59602e20d8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00635\n"
     ]
    }
   ],
   "source": [
    "# probability of the sentence\n",
    "final_probab = parse_table[0][4]\n",
    "total_sentence_probab = 0\n",
    "for item in list(final_probab):\n",
    "    total_sentence_probab += item[1]\n",
    "    \n",
    "print(total_sentence_probab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc6ad26-6bda-4afb-9f35-80f66e09b074",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
